{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GK9101 Data Science \"Neuronale Netzwerke - pytorch/TensorFlow\"\n",
    "\n",
    "Andreas Sünder - 16.11.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch arbeitet mit sogenannten Tensor-Objekten, die Arrays recht ähnlich sind. Mit `torch.zeros()` lassen sich (mehrdimensionale) Tensors mit Nullen initialisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `Tensor.dtype`, `Tensor.shape` (bzw. `Tensor.size()`) lassen sich wichtige Basisinformationen ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.dtype)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardmäßig wird 32-bit Floating Point Precision verwendet; dies die Genauigkeit lässt sich auch über einen Parameter beim Initalisieren ändern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.ones((5, 3))\n",
    "i.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese \"Gewichte\" können auch zufällig initialisiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Tensors lassen sich auch einfache Rechenoperationen durchführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones(2, 3)\n",
    "twos = torch.ones(2, 3) * 2 # Multiplikation mit Skalar\n",
    "\n",
    "# Tensor-Addition (geht, weil gleiche Dimensionen)\n",
    "threes = ones + twos\n",
    "threes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weitere mathematische Operationen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte zwischen -1 und 1\n",
    "r = (torch.rand(2, 2) - 0.5)\n",
    "print('Werte zwischen 0 und 1:', r)\n",
    "\n",
    "# Beträge der einzelnen Werte\n",
    "print('Beträge:', r.abs())\n",
    "\n",
    "# Trigonometrische Funktionen\n",
    "print('Sinus:', r.sin())\n",
    "print('Cosinus:', r.cos())\n",
    "print('Tangens:', r.tan())\n",
    "print('Asinus:', r.asin())\n",
    "\n",
    "# Lineare Algebra\n",
    "print('Determinate:', torch.det(r))\n",
    "print('Singulärwertzerlegung:', torch.svd(r))\n",
    "\n",
    "# Statistik\n",
    "print('Standardabweichung:', torch.std_mean(r))\n",
    "print('Minimum:', r.min())\n",
    "print('Maximum:', r.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LeNet, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "    x = x.view(-1, self.num_flat_features(x))\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "\n",
    "  def num_flat_features(self, x):\n",
    "    size = x.size()[1:]\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "        num_features *= s\n",
    "    return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun unser Modell aufrufen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet()\n",
    "print(net) # Ausgabe der Struktur des Netzes\n",
    "\n",
    "input = torch.rand(1, 1, 32, 32)\n",
    "print('Input image shape:', input.shape)\n",
    "\n",
    "output = net(input) # ruft intern forward() auf\n",
    "print('Raw output:', output)\n",
    "print('Output shape:', output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trainieren eines Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ziel ist es nun, ein Modell zu trainieren, welches auf Basis des CIFAR10-Datensatzes Bilder klassifizieren kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(train, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(test, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Trainieren verwenden wir folgendes Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = x.view(-1, 16 * 5 * 5)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Evaluieren des finalen Modells ist eine entsprechende Loss-Funktion notwendig (hier Cross-Entropy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des Weiteren wird ein Optimizer benötigt. Der Optimizer selbst ist der Algorithmus, der die Gewichte des Modells anpasst. Hier verwenden wir Stochastic Gradient Descent (SGD):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Trainieren verwenden wir eine eigene Training-Loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.224\n",
      "[2,  2000] loss: 1.677\n",
      "[3,  2000] loss: 1.461\n",
      "[4,  2000] loss: 1.349\n",
      "[5,  2000] loss: 1.254\n",
      "[6,  2000] loss: 1.178\n",
      "[7,  2000] loss: 1.129\n",
      "[8,  2000] loss: 1.074\n",
      "[9,  2000] loss: 1.023\n",
      "[10,  2000] loss: 0.985\n",
      "[11,  2000] loss: 0.938\n",
      "[12,  2000] loss: 0.906\n",
      "[13,  2000] loss: 0.874\n",
      "[14,  2000] loss: 0.833\n",
      "[15,  2000] loss: 0.799\n",
      "[16,  2000] loss: 0.774\n",
      "[17,  2000] loss: 0.752\n",
      "[18,  2000] loss: 0.720\n",
      "[19,  2000] loss: 0.700\n",
      "[20,  2000] loss: 0.677\n",
      "[21,  2000] loss: 0.645\n",
      "[22,  2000] loss: 0.632\n",
      "[23,  2000] loss: 0.606\n",
      "[24,  2000] loss: 0.576\n",
      "[25,  2000] loss: 0.569\n",
      "[26,  2000] loss: 0.552\n",
      "[27,  2000] loss: 0.532\n",
      "[28,  2000] loss: 0.514\n",
      "[29,  2000] loss: 0.498\n",
      "[30,  2000] loss: 0.479\n",
      "[31,  2000] loss: 0.461\n",
      "[32,  2000] loss: 0.455\n",
      "[33,  2000] loss: 0.432\n",
      "[34,  2000] loss: 0.436\n",
      "[35,  2000] loss: 0.412\n",
      "[36,  2000] loss: 0.404\n",
      "[37,  2000] loss: 0.376\n",
      "[38,  2000] loss: 0.381\n",
      "[39,  2000] loss: 0.362\n",
      "[40,  2000] loss: 0.367\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "log_interval = 2000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  running_loss = 0.0\n",
    "  \n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    if i % log_interval == log_interval - 1:\n",
    "      print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / log_interval))\n",
    "      running_loss = 0.0\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun evaluieren wir das Modell auf dem Test-Datensatz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "  for data in testloader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Schluss speichern wir das trainierte Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'cifar_net.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
